{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu+YlkGkJZQUfMe+M9Hxez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TamizharasanG/PhonePePulse/blob/main/PhonePe_Pulse_Dashboard1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "! git clone \"https://github.com/PhonePe/pulse\""
      ],
      "metadata": {
        "id": "QphXLI9q49u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LizUgvzNuY_9",
        "outputId": "382a0b84-052e-4b04-f1c7-4d38bc8d53e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting etl.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile etl.py\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "#!git clone \"https://github.com/PhonePe/pulse\"\n",
        "\n",
        "input_file = Path.cwd() / \"pulse\"\n",
        "file = list(input_file.rglob(\"*.json*\"))\n",
        "\n",
        "end_val = []\n",
        "for i in file:\n",
        "  full_path = i.absolute()\n",
        "  my_path = full_path.as_posix()\n",
        "  val = my_path.split(\"/\")\n",
        "  num = 0\n",
        "  for j in val:\n",
        "    if j == \"aggregated\":\n",
        "      num+= 1\n",
        "    elif j == \"map\":\n",
        "      num+=100\n",
        "    elif j == \"top\":\n",
        "      num+= 200\n",
        "    elif j == \"state\":\n",
        "      num +=50\n",
        "    elif j == \"transaction\":\n",
        "      num+= 10\n",
        "    elif j == \"user\":\n",
        "      num+= 25\n",
        "  new_val = str(num)+\"!\"+my_path\n",
        "  end_val.append(new_val)\n",
        "\n",
        "agg_trans_year_list = []\n",
        "agg_trans_state_list = []\n",
        "agg_user_year_list = []\n",
        "agg_user_state_list = []\n",
        "map_trans_year_list = []\n",
        "map_trans_state_list = []\n",
        "map_user_year_list = []\n",
        "map_user_state_list = []\n",
        "top_trans_year_list = []\n",
        "top_trans_state_list = []\n",
        "top_user_year_list = []\n",
        "top_user_state_list = []\n",
        "for i in end_val:\n",
        "  tr = i.split(\"!\")\n",
        "  if int(tr[0]) == 11:\n",
        "    agg_trans_year_list.append(tr[1])\n",
        "  elif int(tr[0]) == 61:\n",
        "    agg_trans_state_list.append(tr[1])\n",
        "  elif int(tr[0]) == 26:\n",
        "    agg_user_year_list.append(tr[1])\n",
        "  elif int(tr[0]) == 76:\n",
        "    agg_user_state_list.append(tr[1])\n",
        "  elif int(tr[0]) == 110:\n",
        "    map_trans_year_list.append(tr[1])\n",
        "  elif int(tr[0]) == 160:\n",
        "    map_trans_state_list.append(tr[1])\n",
        "  elif int(tr[0]) == 125:\n",
        "    map_user_year_list.append(tr[1])\n",
        "  elif int(tr[0]) == 175:\n",
        "    map_user_state_list.append(tr[1])\n",
        "  elif int(tr[0]) == 210:\n",
        "    top_trans_year_list.append(tr[1])\n",
        "  elif int(tr[0]) == 260:\n",
        "    top_trans_state_list.append(tr[1])\n",
        "  elif int(tr[0]) == 225:\n",
        "    top_user_year_list.append(tr[1])\n",
        "  elif int(tr[0]) == 275:\n",
        "    top_user_state_list.append(tr[1])\n",
        "\n",
        "#logic 1 : Agg_trans_year\n",
        "def agg_trans_year(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  category = []\n",
        "  count = []\n",
        "  amount = []\n",
        "  year = []\n",
        "  quadrant = []\n",
        "  for i in df_raw.iloc[2, 2]:\n",
        "    category.append(i[\"name\"])\n",
        "    count.append(i[\"paymentInstruments\"][0][\"count\"])\n",
        "    amount.append(i[\"paymentInstruments\"][0][\"amount\"])\n",
        "    year.append(int(x.split(\"/\")[-2]))\n",
        "    quadrant.append(int(x.split(\"/\")[-1].split(\".\")[0]))\n",
        "  df = pd.DataFrame({\"Year\" : year,\n",
        "                     \"Quadrant\" : quadrant,\n",
        "                     \"Category\" : category,\n",
        "                     \"Total Count\" : count,\n",
        "                     \"Total Amount\" : amount,\n",
        "                          })\n",
        "\n",
        "  return df\n",
        "\n",
        "#function for combining data from all links\n",
        "def tabulate_agg_trans_year(x):\n",
        "  df1 = agg_trans_year(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(agg_trans_year(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "#logic 2 : Agg_trans_state\n",
        "def agg_trans_state(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  name = x.split(\"/\")[-3].replace(\"&\", \" \").replace(\"-\", \" \").title()\n",
        "  name = \" \".join(name.split())\n",
        "  year = int(x.split(\"/\")[-2])\n",
        "  quadrant = int(x.split(\"/\")[-1].split(\".\")[0])\n",
        "\n",
        "  info = {\"State Name\" : name, \"Year\" : year, \"Quadrant\" : quadrant}\n",
        "  for i in df_raw.iloc[2, 2]:\n",
        "    info[i[\"name\"]+\" \"+\"Count\"] = i[\"paymentInstruments\"][0][\"count\"]\n",
        "    info[i[\"name\"]+\" \"+\"Value\"] = i[\"paymentInstruments\"][0][\"amount\"]\n",
        "\n",
        "  df = pd.DataFrame(info, index = [0])\n",
        "  return df\n",
        "\n",
        "#function for combining data from all links\n",
        "def tabulate_agg_trans_state(x):\n",
        "  df1 = agg_trans_state(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(agg_trans_state(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "#logic 3 : Agg_user_year\n",
        "def agg_user_year(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  year = int(x.split(\"/\")[-2])\n",
        "  quadrant = int(x.split(\"/\")[-1].split(\".\")[0])\n",
        "  info = {\"Year\" : year, \"Quadrant\" : quadrant}\n",
        "  info[\"Registered Users\"] = df_raw.iloc[0, 2][\"registeredUsers\"]\n",
        "  info[\"App Opens\"] = df_raw.iloc[0, 2][\"appOpens\"]\n",
        "  if df_raw.iloc[1, 2] !=  None:\n",
        "    for i in df_raw.iloc[1, 2]:\n",
        "      info[i[\"brand\"]+\" \"+\"Users\"] = i[\"count\"]\n",
        "\n",
        "  df = pd.DataFrame(info, index = [0])\n",
        "  return df\n",
        "\n",
        "#function for combining all data from the links\n",
        "def tabulate_agg_user_year(x):\n",
        "  df1 = agg_user_year(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(agg_user_year(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "#logic 4 : Agg_user_state\n",
        "def agg_user_state(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  year = int(x.split(\"/\")[-2])\n",
        "  quadrant = int(x.split(\"/\")[-1].split(\".\")[0])\n",
        "  name = x.split(\"/\")[-3].replace(\"&\", \" \").replace(\"-\", \" \").replace(\" \", \" \").title()\n",
        "  name = \" \".join(name.split())\n",
        "  info = {\"State Name\" : name, \"Year\" : year, \"Quadrant\" : quadrant}\n",
        "  info[\"Registered Users\"] = df_raw.iloc[0, 2][\"registeredUsers\"]\n",
        "  info[\"App Opens\"] = df_raw.iloc[0, 2][\"appOpens\"]\n",
        "  if df_raw.iloc[1, 2] !=  None:\n",
        "    for i in df_raw.iloc[1, 2]:\n",
        "      info[i[\"brand\"]+\" \"+\"Users\"] = i[\"count\"]\n",
        "\n",
        "  df = pd.DataFrame(info, index = [0])\n",
        "  return df\n",
        "\n",
        "#function for combining all data from the links\n",
        "def tabulate_agg_user_state(x):\n",
        "  df1 = agg_user_state(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(agg_user_state(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "#logic 5: Map_trans_state\n",
        "def map_trans_state(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  st_name = x.split(\"/\")[-3].replace(\"&\", \" \").replace(\"-\", \" \").replace(\" \", \" \").title()\n",
        "  st_name = \" \".join(st_name.split())\n",
        "  year = int(x.split(\"/\")[-2])\n",
        "  quadrant = int(x.split(\"/\")[-1][0])\n",
        "  state_name = []\n",
        "  d_name = []\n",
        "  transaction_count = []\n",
        "  transaction_amount = []\n",
        "  for i in df_raw.iloc[0, 2]:\n",
        "    state_name.append(st_name)\n",
        "    d_name.append(i[\"name\"].title())\n",
        "    transaction_count.append(i[\"metric\"][0][\"count\"])\n",
        "    transaction_amount.append(i[\"metric\"][0][\"amount\"])\n",
        "  \n",
        "  info = {\"State Name\" : state_name,\n",
        "          \"District Name\" : d_name,\n",
        "          \"Transaction Count\": transaction_count,\n",
        "          \"Transaction Amount\" : transaction_amount}\n",
        "\n",
        "  df = pd.DataFrame(info)\n",
        "  y = [year for i in range(df.shape[0])]\n",
        "  q = [quadrant for i in range(df.shape[0])]\n",
        "  df.insert(0, \"Year\", y)\n",
        "  df.insert(1, \"Quadrant\", q)\n",
        "\n",
        "  return df\n",
        "\n",
        "#function for combining all data from the links\n",
        "def tabulate_map_trans_state(x):\n",
        "  df1 = map_trans_state(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(map_trans_state(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "#logic 6: Map_user_state\n",
        "def map_user_state(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  st_name = x.split(\"/\")[-3].replace(\"&\", \" \").replace(\"-\", \" \").replace(\" \", \" \").title()\n",
        "  st_name = \" \".join(st_name.split())\n",
        "  year = int(x.split(\"/\")[-2])\n",
        "  quadrant = int(x.split(\"/\")[-1][0])\n",
        "  state_name = []\n",
        "  d_name = []\n",
        "  registered_users = []\n",
        "  app_opens = []\n",
        "  for i in df_raw.iloc[0, 2]:\n",
        "    state_name.append(st_name)\n",
        "    d_name.append(i.title())\n",
        "    registered_users.append(df_raw.iloc[0, 2][i][\"registeredUsers\"])\n",
        "    app_opens.append((df_raw.iloc[0, 2][i][\"appOpens\"]))\n",
        "  \n",
        "  info = {\"State Name\" : state_name,\n",
        "          \"District Name\" : d_name,\n",
        "          \"Registered Users\": registered_users,\n",
        "          \"App Opens\" : app_opens}\n",
        "  \n",
        "  df = pd.DataFrame(info)\n",
        "  y = [year for i in range(df.shape[0])]\n",
        "  q = [quadrant for i in range(df.shape[0])]\n",
        "  df.insert(0, \"Year\", y)\n",
        "  df.insert(1, \"Quadrant\", q)\n",
        "  return df\n",
        "\n",
        "\n",
        "#function for combining all data from the links\n",
        "def tabulate_map_user_state(x):\n",
        "  df1 = map_user_state(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(map_user_state(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "#logic 7: Top_trans_year\n",
        "def top_trans_year(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  year = int(x.split(\"/\")[-2])\n",
        "  quadrant = int(x.split(\"/\")[-1][0])\n",
        "  city_name = []\n",
        "  city_trans_count = []\n",
        "  city_trans_amount = []\n",
        "  pin_trans = []\n",
        "  pin_trans_count = []\n",
        "  pin_trans_amount = []\n",
        "  state_name = []\n",
        "  state_trans_count = []\n",
        "  state_trans_amount = []\n",
        "  y = []\n",
        "  q = []\n",
        "  for i in df_raw.iloc[0, 2]:\n",
        "    y.append(year)\n",
        "    q.append(quadrant)\n",
        "    city_name.append(i[\"entityName\"].title())\n",
        "    city_trans_count.append(i[\"metric\"][\"count\"])\n",
        "    city_trans_amount.append(i[\"metric\"][\"amount\"])\n",
        "  for i in df_raw.iloc[1, 2]:\n",
        "    pin_trans.append(i[\"entityName\"].title())\n",
        "    pin_trans_count.append(i[\"metric\"][\"count\"])\n",
        "    pin_trans_amount.append(i[\"metric\"][\"amount\"])\n",
        "  for i in df_raw.iloc[2, 2]:\n",
        "    state_name.append(i[\"entityName\"].title())\n",
        "    state_trans_count.append(i[\"metric\"][\"count\"])\n",
        "    state_trans_amount.append(i[\"metric\"][\"amount\"])\n",
        "  \n",
        "  info = {\"Year\" : y,\n",
        "          \"Quadrant\" : q,\n",
        "          \"Top City Name\" : city_name,\n",
        "          \"City Transaction Count\" : city_trans_count,\n",
        "          \"City Transaction Amount\" : city_trans_amount,\n",
        "          \"Top Pincode\" : pin_trans,\n",
        "          \"Pincode Transaction Count\" : pin_trans_count,\n",
        "          \"Pincode Transaction Amount\" : pin_trans_amount,\n",
        "          \"Top State Name\" : state_name,\n",
        "          \"State Transaction Count\" : state_trans_count,\n",
        "          \"State Transaction Amount\" : state_trans_amount}\n",
        "\n",
        "  df = pd.DataFrame(info)\n",
        "  return df\n",
        "\n",
        "\n",
        "#function for combining all data from the links\n",
        "def tabulate_top_trans_year(x):\n",
        "  df1 = top_trans_year(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(top_trans_year(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "#logic 8: Top_trans_state\n",
        "def top_trans_state(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  st_name = x.split(\"/\")[-3].replace(\"&\", \" \").replace(\"-\", \" \").replace(\" \", \" \").title()\n",
        "  st_name = \" \".join(st_name.split())\n",
        "  year = int(x.split(\"/\")[-2])\n",
        "  quadrant = int(x.split(\"/\")[-1][0])\n",
        "  district_name = []\n",
        "  district_trans_count = []\n",
        "  district_trans_amount = []\n",
        "  pin_trans = []\n",
        "  pin_trans_count = []\n",
        "  pin_trans_amount = []\n",
        "  for i in df_raw.iloc[0, 2]:\n",
        "    district_name.append(i[\"entityName\"].title())\n",
        "    district_trans_count.append(i[\"metric\"][\"count\"])\n",
        "    district_trans_amount.append(i[\"metric\"][\"amount\"])\n",
        "  for i in df_raw.iloc[1, 2]:\n",
        "    pin_trans.append(i[\"entityName\"])\n",
        "    pin_trans_count.append(i[\"metric\"][\"count\"])\n",
        "    pin_trans_amount.append(i[\"metric\"][\"amount\"])\n",
        "\n",
        "  from numpy import NaN\n",
        "  if len(district_name) == len(pin_trans):\n",
        "    pass\n",
        "  elif len(district_name) != len(pin_trans):\n",
        "    z = abs(len(district_name) - len(pin_trans))\n",
        "    if len(district_name) < len(pin_trans):\n",
        "      adjust = [NaN for i in range(z)]\n",
        "      district_name.extend(adjust)\n",
        "      district_trans_count.extend(adjust)\n",
        "      district_trans_amount.extend(adjust)\n",
        "\n",
        "  info = {\"Top District Name\" : district_name,\n",
        "          \"District Transaction Count\" : district_trans_count,\n",
        "          \"District Transaction Amount\" : district_trans_amount,\n",
        "          \"Top Pincode\" : pin_trans,\n",
        "          \"Pincode Transaction Count\" : pin_trans_count,\n",
        "          \"Pincode Transaction Amount\" : pin_trans_amount}\n",
        "  df = pd.DataFrame(info)\n",
        "  y = [year for i in range(df.shape[0])]\n",
        "  q = [quadrant for i in range(df.shape[0])]\n",
        "  s = [st_name for i in range(df.shape[0])]\n",
        "  df.insert(0, \"State Name\" , s)\n",
        "  df.insert(1, \"Year\", y)\n",
        "  df.insert(2, \"Quadrant\", q)\n",
        "  return df\n",
        "\n",
        "\n",
        "#function for combining all data from the links\n",
        "def tabulate_top_trans_state(x):\n",
        "  df1 = top_trans_state(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(top_trans_state(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "#logic 9 : Top_user_year\n",
        "def top_user_year(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  year = int(x.split(\"/\")[-2])\n",
        "  quadrant = int(x.split(\"/\")[-1][0])\n",
        "  district_name = []\n",
        "  district_reg_users = []\n",
        "  pin = []\n",
        "  pin_reg_users = []\n",
        "  state_name = []\n",
        "  state_reg_users = []\n",
        "  for i in df_raw.iloc[0, 2]:\n",
        "    district_name.append(i[\"name\"].title())\n",
        "    district_reg_users.append(i[\"registeredUsers\"])\n",
        "  for i in df_raw.iloc[1, 2]:\n",
        "    pin.append(i[\"name\"])\n",
        "    pin_reg_users.append(i[\"registeredUsers\"])\n",
        "  for i in df_raw.iloc[2, 2]:\n",
        "    state_name.append(i[\"name\"].title())\n",
        "    state_reg_users.append(i[\"registeredUsers\"])\n",
        "\n",
        "  info = {\"Top District Name\" : district_name,\n",
        "          \"District Registered Users Count\" : district_reg_users,\n",
        "          \"Top Pincode\" : pin,\n",
        "          \"Pincode Registered Users Count\" : pin_reg_users}\n",
        "\n",
        "  df = pd.DataFrame(info)\n",
        "  y = [year for i in range(1, df.shape[0]+1)]\n",
        "  q = [quadrant for i in range(1, df.shape[0]+1)]\n",
        "  df.insert(0, \"Year\", y)\n",
        "  df.insert(1, \"Quadrant\" ,q)\n",
        "  return df\n",
        "  \n",
        "#function for combining all data from the links\n",
        "def tabulate_top_user_year(x):\n",
        "  df1 = top_user_year(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(top_user_year(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "#logic 10 : Top_user_state\n",
        "def top_user_state(x):\n",
        "  df_raw = pd.read_json(x)\n",
        "  st_name = x.split(\"/\")[-3].replace(\"&\", \" \").replace(\"-\", \" \").replace(\" \", \" \").title()\n",
        "  st_name = \" \".join(st_name.split())\n",
        "  year = int(x.split(\"/\")[-2])\n",
        "  quadrant = int(x.split(\"/\")[-1][0])\n",
        "  district_name = []\n",
        "  district_reg_users = []\n",
        "  pin = []\n",
        "  pin_reg_users = []\n",
        "  for i in df_raw.iloc[0, 2]:\n",
        "    district_name.append(i[\"name\"].title())\n",
        "    district_reg_users.append(i[\"registeredUsers\"])\n",
        "  for i in df_raw.iloc[1, 2]:\n",
        "    pin.append(i[\"name\"])\n",
        "    pin_reg_users.append(i[\"registeredUsers\"])\n",
        "\n",
        "  from numpy import NaN\n",
        "  if len(district_name) == len(pin):\n",
        "    pass\n",
        "  elif len(district_name) != len(pin):\n",
        "    z = abs(len(district_name) - len(pin))\n",
        "    if len(district_name) < len(pin):\n",
        "      adjust = [NaN for i in range(z)]\n",
        "      district_name.extend(adjust)\n",
        "      district_reg_users.extend(adjust)\n",
        "\n",
        "  info = {\"Top District Name\" : district_name,\n",
        "          \"District Registered users Count\" : district_reg_users,\n",
        "          \"Top Pincode\" : pin,\n",
        "          \"Pincode Registered Users Count\" : pin_reg_users}\n",
        "  df = pd.DataFrame(info)\n",
        "  y = [year for i in range(df.shape[0])]\n",
        "  q = [quadrant for i in range(df.shape[0])]\n",
        "  s = [st_name for i in range(df.shape[0])]\n",
        "  df.insert(0, \"State Name\" , s)\n",
        "  df.insert(1, \"Year\", y)\n",
        "  df.insert(2, \"Quadrant\", q)\n",
        "  return df\n",
        "\n",
        "#function for combining all data from the links\n",
        "def tabulate_top_user_state(x):\n",
        "  df1 = top_user_state(x[0])\n",
        "  for i in x[1:]:\n",
        "    df1 = df1.append(top_user_state(i))\n",
        "  df1 = df1.sort_values([\"Year\", \"Quadrant\"], ascending = True, ignore_index = True)\n",
        "  return df1\n",
        "\n",
        "Aggrigation_trans_year = tabulate_agg_trans_year(agg_trans_year_list)\n",
        "Aggrigation_trans_state = tabulate_agg_trans_state(agg_trans_state_list)\n",
        "Aggrigation_user_year = tabulate_agg_user_year(agg_user_year_list)\n",
        "Aggrigation_user_state = tabulate_agg_user_state(agg_user_state_list)\n",
        "Map_trans_state = tabulate_map_trans_state(map_trans_state_list)\n",
        "Map_user_state = tabulate_map_user_state(map_user_state_list)\n",
        "Top_trans_year = tabulate_top_trans_year(top_trans_year_list)\n",
        "Top_trans_state = tabulate_top_trans_state(top_trans_state_list)\n",
        "Top_user_year = tabulate_top_user_year(top_user_year_list)\n",
        "Top_user_state = tabulate_top_user_state(top_user_state_list)\n",
        "\n",
        "import sqlite3\n",
        "conn = sqlite3.connect(\"Tamil.db\")\n",
        "cur = conn.cursor()\n",
        "\n",
        "#TABLE 1:\n",
        "cur.execute('''CREATE TABLE IF NOT EXISTS AGGRIGATION_TRANSACTION_YEARWISE(\n",
        "            YEAR INT,\n",
        "            QUADRANT TINYINT,\n",
        "            CATEGORY VARCHAR(30),\n",
        "            TOTAL_COUNT INT,\n",
        "            TOTAL_AMOUNT FLOAT\n",
        ")''')\n",
        "\n",
        "for (i, j) in Aggrigation_trans_year.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO AGGRIGATION_TRANSACTION_YEARWISE VALUES{dp}''')\n",
        "\n",
        "#TABLE 2:\n",
        "cur.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS AGGREGATION_TRANSACTION_STATEWISE(\n",
        "          STATE_NAME VARCHAR(35),\n",
        "          YEAR INT,\n",
        "          QUADRANT TINYINT,\n",
        "          PEER_TO_PEER_PAYMENT_COUNT INT,\n",
        "          PEER_TO_PEER_PAYMENT_VALUE FLOAT,\n",
        "          MERCHANT_PAYMENTS_COUNT INT,\n",
        "          MERCHANT_PAYMENTS_VALUE FLOAT,\n",
        "          RECHARGE_BILL_PAYMENTS_COUNT INT,\n",
        "          RECHARGE_BILL_PAYMENTS_VALUE FLOAT,\n",
        "          FINANCIAL_SERVICES_COUNT INT,\n",
        "          FINANCIAL_SERVICES_VALUE FLOAT,\n",
        "          OTHERS_COUNT INT,\n",
        "          OTHERS_VALUE FLOAT,\n",
        "          TOTAL_COUNT INT,\n",
        "          TOTAL_VALUE FLOAT\n",
        "        )\n",
        "''')\n",
        "#since the numeric column data is filled with nan we are replacing nan with 0\n",
        "Aggrigation_trans_state.isnull().sum()\n",
        "Aggrigation_trans_state.fillna(0, axis = 1, inplace = True)\n",
        "\n",
        "#Overall aggrigated count and amount of the states over Years\n",
        "count_cols = []\n",
        "val_cols = []\n",
        "for i in Aggrigation_trans_state.columns:\n",
        "  if i.endswith(\"Count\"):\n",
        "    count_cols.append(i)\n",
        "  elif i.endswith(\"Value\"):\n",
        "    val_cols.append(i)\n",
        "\n",
        "count_cols.insert(0, \"State Name\")\n",
        "count_df = Aggrigation_trans_state[count_cols]\n",
        "count_col_new = count_df.sum(axis = 1, skipna = True, numeric_only=True).tolist()\n",
        "\n",
        "val_cols.insert(0, \"State Name\")\n",
        "val_df = Aggrigation_trans_state[val_cols]\n",
        "val_col_new = val_df.sum(axis = 1, skipna = True, numeric_only=True).tolist()\n",
        "\n",
        "#Adding the new columns to the datafram \n",
        "Aggrigation_trans_state[\"Total Count\"] = count_col_new\n",
        "Aggrigation_trans_state[\"Total Amount\"] = val_col_new\n",
        "\n",
        "for (i, j) in Aggrigation_trans_state.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO AGGREGATION_TRANSACTION_STATEWISE VALUES{dp}''')\n",
        "\n",
        "#TABLE 3:\n",
        "cur.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS AGGREGATED_USER_YEARWISE(\n",
        "          YEAR INT,\n",
        "          QUADRANT INT,\n",
        "          REGISTERED_USERS INT,\n",
        "          APP_OPENS INT,\n",
        "          XIAOMI_USERS INT,\n",
        "          SAMSUNG_USERS INT,\n",
        "          VIVO_USERS INT,\n",
        "          OPPO_USERS INT,\n",
        "          REALME_USERS INT,\n",
        "          APPLE_USERS INT,\n",
        "          MOTOROLA_USERS INT,\n",
        "          ONEPLUS_USERS INT,\n",
        "          HUAWEI_USERS INT,\n",
        "          TECHNO_USERS INT,\n",
        "          OTHERS_USERS INT,\n",
        "          LENOVO_USERS INT\n",
        "        )\n",
        "''')\n",
        "#since the data was updated 6 month once these datas are left null for long days so it is filled with 0\n",
        "Aggrigation_user_year_nonull = Aggrigation_user_year.iloc[:-3].copy()\n",
        "Aggrigation_user_year_nonull.fillna(0, inplace = True)\n",
        "\n",
        "#columns containing all values are updated into database seperately\n",
        "for (i, j) in Aggrigation_user_year_nonull.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO AGGREGATED_USER_YEARWISE VALUES{dp}''')\n",
        "\n",
        "#since some records was not uploaded the null columns are uploades seperately\n",
        "for (i, j) in Aggrigation_user_year.iloc[-3:, :4].iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO AGGREGATED_USER_YEARWISE(YEAR, QUADRANT, REGISTERED_USERS, APP_OPENS) VALUES{dp}''')\n",
        "\n",
        "#TABLE : 4\n",
        "cur.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS AGGREGATED_USER_STATEWISE(\n",
        "          STATE_NAME VARCHAR(35),\n",
        "          YEAR INT,\n",
        "          QUADRANT INT,\n",
        "          REGISTERED_USERS INT,\n",
        "          APP_OPENS INT,\n",
        "          XIAOMI_USERS INT,\n",
        "          VIVO_USERS INT,\n",
        "          OPPO_USERS INT,\n",
        "          SAMSUNG_USERS INT, \n",
        "          REALME_USERS INT,\n",
        "          APPLE_USERS INT,\n",
        "          HUAWEI_USERS INT,\n",
        "          GIONEE_USERS INT,\n",
        "          ONEPLUS_USERS INT,\n",
        "          TECHNO_USERS INT,\n",
        "          OTHERS_USERS INT,\n",
        "          ASUS_USERS INT,\n",
        "          MOTOROLA_USERS INT,\n",
        "          LENOVO_USERS INT,\n",
        "          COOLPAD_USERS INT,\n",
        "          MICROMAX_USERS,\n",
        "          HMD_GLOBAL_USERS,\n",
        "          INFINIX_USERS,\n",
        "          LAVA_USERS,\n",
        "          LYF_USERS INT         \n",
        "        )\n",
        "''')\n",
        "Aggrigation_user_state_nonull = Aggrigation_user_state.iloc[:612, :].copy()\n",
        "Aggrigation_user_state_nonull.fillna(0, inplace = True)\n",
        "Aggrigation_user_state_null = Aggrigation_user_state.iloc[612:, :5].copy()\n",
        "#columns containing all values are updated into database seperately\n",
        "for (i, j) in Aggrigation_user_state_nonull.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO AGGREGATED_USER_STATEWISE VALUES{dp}''')\n",
        "\n",
        "#since some records was not uploaded the null columns are uploades seperately\n",
        "for (i, j) in Aggrigation_user_state_null.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO AGGREGATED_USER_STATEWISE(STATE_NAME, YEAR, QUADRANT, REGISTERED_USERS, APP_OPENS) VALUES{dp}''')\n",
        "\n",
        "#TABLE : 5\n",
        "cur.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS MAP_TRANSACTION_STATEWISE(\n",
        "              YEAR INT,\n",
        "              QUADRANT TINYINT,\n",
        "              STATE_NAME VARCHAR(35),\n",
        "              DISTRICT_NAME VARCHAR(50),\n",
        "              TRANSACTION_COUNT INT,\n",
        "              TRANSACTION_AMOUNT FLOAT\n",
        "            )\n",
        "''')\n",
        "for (i, j) in Map_trans_state.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO MAP_TRANSACTION_STATEWISE VALUES{dp}''')\n",
        "\n",
        "#TABLE : 6\n",
        "cur.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS MAP_USER_STATEWISE(\n",
        "              YEAR INT,\n",
        "              QUADRANT TINYINT,\n",
        "              STATE_NAME VARCHAR(35),\n",
        "              DISTRICT_NAME VARCHAR(50),\n",
        "              REGISTERED_USERS INT,\n",
        "              APP_OPENS INT\n",
        "            )\n",
        "''')\n",
        "for (i, j) in Map_user_state.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO MAP_USER_STATEWISE VALUES{dp}''')\n",
        "\n",
        "#TABLE : 7\n",
        "cur.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS TOP_TRANSACTION_YEARWISE(\n",
        "              YEAR INT,\n",
        "              QUADRANT TINYINT,\n",
        "              TOP_CITY_NAME VARCHAR(30),\n",
        "              CITY_TRANSACTION_COUNT INT,\n",
        "              CITY_TRANSACTION_AMOUNT FLOAT,\n",
        "              TOP_PINCODE VARCHAR(6),\n",
        "              PINCODE_TRANSACTION_COUNT INT,\n",
        "              PINCODE_TRANSACTION_AMOUNT FLOAT,\n",
        "              TOP_STATE_NAME VARCHAR(35),\n",
        "              STATE_TRANSACTION_COUNT INT,\n",
        "              STATE_TRANSACTION_AMOUNT FLOAT\n",
        "            )\n",
        "''')\n",
        "for (i, j) in Top_trans_year.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO TOP_TRANSACTION_YEARWISE VALUES{dp}''')\n",
        "\n",
        "#TABLE : 8\n",
        "cur.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS TOP_TRANSACTION_STATEWISE(\n",
        "              STATE_NAME VARCHAR(35),\n",
        "              YEAR INT,\n",
        "              QUADRANT TINYINT,\n",
        "              TOP_DISTRICT_NAME VARCHAR(50),\n",
        "              DISTRICT_TRANSACTION_COUNT INT,\n",
        "              DISTRICT_TRANSACTION_AMOUNT FLOAT,\n",
        "              TOP_PINCODE VARCHAR(6),\n",
        "              PINCODE_TRANSACTION_COUNT INT,\n",
        "              PINCODE_TRANSACTION_AMOUNT FLOAT\n",
        "            )\n",
        "''')\n",
        "#Since some small states were present in the table some have less than 10 districts and have more pincodes. the district columns were left as null for those states. So the null valued columns are seperated and inserted seperately\n",
        "Null_valued_index_pin = Top_trans_state[Top_trans_state[\"Top Pincode\"].isna()].index\n",
        "Top_trans_state.drop(Null_valued_index_pin, inplace = True)\n",
        "Top_trans_state_nonull = Top_trans_state.copy() \n",
        "Top_trans_state_nonull.dropna(axis = 0, inplace = True)\n",
        "\n",
        "for (i, j) in Top_trans_state_nonull.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO TOP_TRANSACTION_STATEWISE VALUES{dp}''')\n",
        "\n",
        "for (i, j) in Top_trans_state[Top_trans_state[\"Top District Name\"].isna()].iloc[: , [0, 1, 2, 6, 7, 8]].iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO TOP_TRANSACTION_STATEWISE(STATE_NAME, YEAR, QUADRANT,TOP_PINCODE, PINCODE_TRANSACTION_COUNT, PINCODE_TRANSACTION_AMOUNT) VALUES{dp}''')\n",
        "\n",
        "#TABLE : 9\n",
        "cur.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS TOP_USER_YEARWISE(\n",
        "              YEAR INT,\n",
        "              QUADRANT TINYINT,\n",
        "              TOP_DISTRICT_NAME VARCHAR(30),\n",
        "              DISTRICT_REGISTERED_USERS_COUNT INT,\n",
        "              TOP_PINCODE VARCHAR(6),\n",
        "              PINCODE_REGISTERED_USERS_COUNT INT\n",
        "            )\n",
        "''')\n",
        "for (i, j) in Top_user_year.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO TOP_USER_YEARWISE VALUES{dp}''')\n",
        "\n",
        "#TABLE : 10\n",
        "cur.execute('''\n",
        "              CREATE TABLE IF NOT EXISTS TOP_USER_STATEWISE(\n",
        "                STATE_NAME VARCHAR(35),\n",
        "                YEAR INT,\n",
        "                QUADRANT TINYINT,\n",
        "                TOP_DISTRICT_NAME VARCHAR(50),\n",
        "                DISTRICT_REGISTERED_USERS_COUNT INT,\n",
        "                TOP_PINCODE VARCHAR(6),\n",
        "                PINCODE_REGISTERED_USERS_COUNT INT\n",
        "              )\n",
        "''')\n",
        "#Since some small states were present in the table some have less than 10 districts and have more pincodes. the district columns were left as null for those states. So the null valued columns are seperated and inserted seperately\n",
        "Top_user_state_nonull = Top_user_state.copy() \n",
        "Top_user_state_nonull.dropna(axis = 0, inplace = True)\n",
        "for (i, j) in Top_user_state_nonull.iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO TOP_USER_STATEWISE VALUES{dp}''')\n",
        "\n",
        "for (i, j) in Top_user_state[Top_user_state[\"Top District Name\"].isna()].iloc[:, [0, 1,2, 5, 6]].iterrows():\n",
        "  dp = tuple(j)\n",
        "  cur.execute(f'''INSERT INTO TOP_USER_STATEWISE(STATE_NAME, YEAR, QUADRANT,TOP_PINCODE, PINCODE_REGISTERED_USERS_COUNT) VALUES{dp}''')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#fetching the inserted data TABLE : 1\n",
        "fetch_data1 = cur.execute(\"select * from AGGRIGATION_TRANSACTION_YEARWISE\").fetchall()\n",
        "\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(AGGRIGATION_TRANSACTION_YEARWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df1 = pd.DataFrame(fetch_data1, columns = cols)\n",
        "\n",
        "#fetching the inserted data TABLE : 2\n",
        "fetch_data2 = cur.execute(\"select * from AGGREGATION_TRANSACTION_STATEWISE\")\n",
        "fetch_data2 = cur.fetchall()\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(AGGREGATION_TRANSACTION_STATEWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df2 = pd.DataFrame(fetch_data2, columns = cols)\n",
        "\n",
        "#fetching the inserted data TABLE : 3\n",
        "fetch_data3 = cur.execute(\"select * from AGGREGATED_USER_YEARWISE\")\n",
        "fetch_data3 = cur.fetchall()\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(AGGREGATED_USER_YEARWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df3 = pd.DataFrame(fetch_data3, columns = cols)\n",
        "\n",
        "#fetching the inserted data TABLE : 4\n",
        "fetch_data4 = cur.execute(\"select * from AGGREGATED_USER_STATEWISE\")\n",
        "fetch_data4 = cur.fetchall()\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(AGGREGATED_USER_STATEWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df4 = pd.DataFrame(fetch_data4, columns = cols)\n",
        "\n",
        "#fetching the inserted data TABLE : 5\n",
        "fetch_data5 = cur.execute(\"select * from MAP_TRANSACTION_STATEWISE\")\n",
        "fetch_data5 = cur.fetchall()\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(MAP_TRANSACTION_STATEWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df5 = pd.DataFrame(fetch_data5, columns = cols)\n",
        "\n",
        "#fetching the inserted data TABLE : 6\n",
        "fetch_data6 = cur.execute(\"select * from MAP_USER_STATEWISE\")\n",
        "fetch_data6 = cur.fetchall()\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(MAP_USER_STATEWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df6 = pd.DataFrame(fetch_data6, columns = cols)\n",
        "\n",
        "#TABLE : 7\n",
        "#fetching the inserted data\n",
        "fetch_data7 = cur.execute(\"select * from TOP_TRANSACTION_YEARWISE\")\n",
        "fetch_data7 = cur.fetchall()\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(TOP_TRANSACTION_YEARWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df7 = pd.DataFrame(fetch_data7, columns = cols)\n",
        "\n",
        "#fetching the inserted data TABLE : 8\n",
        "fetch_data8 = cur.execute(\"select * from TOP_TRANSACTION_STATEWISE\")\n",
        "fetch_data8 = cur.fetchall()\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(TOP_TRANSACTION_STATEWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df8 = pd.DataFrame(fetch_data8, columns = cols)\n",
        "\n",
        "#fetching the inserted data TABLE : 9\n",
        "fetch_data9 = cur.execute(\"select * from TOP_USER_YEARWISE\")\n",
        "fetch_data9 = cur.fetchall()\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(TOP_USER_YEARWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df9 = pd.DataFrame(fetch_data9, columns = cols)\n",
        "\n",
        "#fetching the inserted data TABLE : 10\n",
        "fetch_data10 = cur.execute(\"select * from TOP_USER_STATEWISE\")\n",
        "fetch_data10= cur.fetchall()\n",
        "#fetching the column names of the data\n",
        "cols = []\n",
        "for i in cur.execute(\"PRAGMA table_info(TOP_USER_STATEWISE)\"):\n",
        "  cols.append(i[1])\n",
        "new_df10 = pd.DataFrame(fetch_data10, columns = cols)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile visuvalization.py\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def year_agg_trans(df, yr, qd):\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "  df11 = df\n",
        "\n",
        "  if year == \"All Years\":\n",
        "    df11 = df11\n",
        "  elif year != \"All Years\":\n",
        "    df11 = df11[df11[\"YEAR\"] == year]\n",
        "  \n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df11 = df11\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df11 = df11[df11[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "\n",
        "\n",
        "  from plotly.subplots import make_subplots\n",
        "  import plotly.graph_objects as go\n",
        "\n",
        "  fig = make_subplots(rows=3, cols=2, \n",
        "                      specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "                            [{\"type\": \"pie\"}, {\"type\": \"pie\"}],\n",
        "                            [{\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n",
        "                      subplot_titles=(\"Year vs Transaction count\",\"Year vs Transaction amount\", \"Catogery vs Transaction Count\", \"Catogery vs Transaction amount\",\"Quadrant vs Transaction Count\", \"Quadrant vs Transaction Amount\" ))\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(y = df11.groupby(\"YEAR\").sum()[\"TOTAL_COUNT\"],x = df11.groupby(\"YEAR\").sum().index),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(y = df11.groupby(\"YEAR\").sum()[\"TOTAL_AMOUNT\"],x = df11.groupby(\"YEAR\").sum().index),\n",
        "      row=1, col=2\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(values = df11.groupby(\"CATEGORY\").sum()[\"TOTAL_COUNT\"], labels = df11.groupby(\"CATEGORY\").sum().index),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(values = df11.groupby(\"CATEGORY\").sum()[\"TOTAL_AMOUNT\"], labels = df11.groupby(\"CATEGORY\").sum().index),\n",
        "      row=2, col=2\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(y = df11.groupby(\"QUADRANT\").sum()[\"TOTAL_COUNT\"],x = df11.groupby(\"QUADRANT\").sum().index),\n",
        "      row=3, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(y = df11.groupby(\"QUADRANT\").sum()[\"TOTAL_AMOUNT\"],x = df11.groupby(\"QUADRANT\").sum().index),\n",
        "      row=3, col=2\n",
        "  )\n",
        "\n",
        "  fig.update_layout(height = 1100, width=1000, title_text=\"Aggrigation of yearly transaction\", showlegend=False)\n",
        "  return fig\n",
        "\n",
        "def year_agg_user(df, yr, qd):\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "  df13 = df\n",
        "  #new_df3\n",
        "  if year == \"All Years\":\n",
        "    df13 = df13\n",
        "  elif year != \"All Years\":\n",
        "    df13 = df13[df13[\"YEAR\"] == year]\n",
        "\n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df13 = df13\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df13 = df13[df13[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "  #Since Year 2022 Q -> 2, 3, 4 data was not updated we are considering the data of 2018 to 2022 Q1 for device ratio\n",
        "  st_user_device_year = df13.iloc[:-3, :]\n",
        "\n",
        "  from plotly.subplots import make_subplots\n",
        "  import plotly.graph_objects as go\n",
        "\n",
        "  fig = make_subplots(rows=3, cols=2, \n",
        "                      specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "                             [{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "                             [{\"type\": \"pie\"}, {\"type\": \"pie\"}]],\n",
        "                      subplot_titles=(\"Year vs Registered Users\",\"Year vs App Opens\", \"Quadrant vs Registered Users\", \"Quadrant vs App opens\",\"Users vs Device used\" ))\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(y = df13.groupby(\"YEAR\").sum()[\"REGISTERED_USERS\"],x = df13.groupby(\"YEAR\").sum().index),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(y = df13.groupby(\"YEAR\").sum()[\"APP_OPENS\"],x = df13.groupby(\"YEAR\").sum().index),\n",
        "      row=1, col=2\n",
        "  )\n",
        "\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x =df13.groupby(\"QUADRANT\").sum().iloc[:, 1:3].index, y = df13.groupby(\"QUADRANT\").sum().iloc[:, 1:3][\"REGISTERED_USERS\"]),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x =df13.groupby(\"QUADRANT\").sum().iloc[:, 1:3].index, y = df13.groupby(\"QUADRANT\").sum().iloc[:, 1:3][\"APP_OPENS\"]),\n",
        "      row=2, col=2\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(values = st_user_device_year.groupby(\"YEAR\").sum().sum().tolist()[3:], labels = st_user_device_year.groupby(\"YEAR\").sum().columns[3:]),\n",
        "      row=3, col=1\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  fig.update_layout(height = 1100, width=1000, title_text=\"Aggrigation of yearly users\", showlegend=False)\n",
        "  return fig\n",
        "\n",
        "def state_agg_trans(df1,df2,st, yr, qd):\n",
        "  import pandas as pd\n",
        "  import plotly.express as px\n",
        "\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "  state = st\n",
        "  df12 = df1\n",
        "  df14 = df2\n",
        "  #new_df2\n",
        "  if state == \"All States\":\n",
        "    df12 = df12\n",
        "    df14 = df14\n",
        "  elif state != \"All States\":\n",
        "    df12 = df12[df12[\"STATE_NAME\"] == state]\n",
        "    df14 = df14[df14[\"STATE_NAME\"] == state]\n",
        "  if year == \"All Years\":\n",
        "    df12 = df12\n",
        "    df14 = df14\n",
        "  elif year != \"All Years\":\n",
        "    df12 = df12[df12[\"YEAR\"] == year]\n",
        "    df14 = df14[df14[\"YEAR\"] == year]\n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df12 = df12\n",
        "    df14 = df14\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df12 = df12[df12[\"QUADRANT\"] == quadrant]\n",
        "    df14 = df14[df14[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "  df1214 = df12.iloc[:, [0, 1, 2, -1, -2]].groupby(\"STATE_NAME\").sum().iloc[:, 2:].merge(df14.iloc[:, :5].groupby(\"STATE_NAME\").sum().iloc[:,2:], on = df12.iloc[:, [0, 1, 2, -1, -2]].groupby(\"STATE_NAME\").sum().index, how = \"inner\")\n",
        "  df1214.columns = [\"STATE_NAME\", \"TOTAL_VALUE\", \"TOTAL_COUNT\",\"REGISTERED_USERS\",\"APP_OPENS\"]\n",
        "\n",
        "  fig = px.choropleth(\n",
        "      df1214,\n",
        "      geojson=\"https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson\",\n",
        "      featureidkey='properties.ST_NM',\n",
        "      locations='STATE_NAME',\n",
        "      color= \"TOTAL_VALUE\",\n",
        "      color_continuous_scale='Reds',\n",
        "      hover_name = \"STATE_NAME\",\n",
        "      hover_data = df1214.columns,\n",
        "  )\n",
        "\n",
        "  fig.update_geos(fitbounds=\"locations\", visible=False)\n",
        "\n",
        "  fig.update_layout(\n",
        "      title=dict(\n",
        "              text=\"Aggregated Transaction count state wise\",\n",
        "              xanchor='center',\n",
        "              x=0.5,\n",
        "              yref='paper',\n",
        "              yanchor='bottom',\n",
        "              y=1,\n",
        "              pad={'b':10}),\n",
        "              margin={'r':0,'t':30,'l':0,'b':0},\n",
        "              height=550,\n",
        "              width=900\n",
        "        )\n",
        "  return fig\n",
        "\n",
        "\n",
        "\n",
        "def state_map_trans(df, st, yr, qd):\n",
        "  from plotly.subplots import make_subplots\n",
        "  import plotly.graph_objects as go\n",
        "\n",
        "  #new_df5\n",
        "\n",
        "\n",
        "  state = st\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "  df15 = df\n",
        "  if state == \"All States\":\n",
        "    df15 = df15\n",
        "  elif state != \"All States\":\n",
        "    df15 = df15[df15[\"STATE_NAME\"] == state]\n",
        "\n",
        "  if year == \"All Years\":\n",
        "    df15 = df15\n",
        "  elif year != \"All Years\":\n",
        "    df15 = df15[df15[\"YEAR\"] == year]\n",
        "\n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df15 = df15\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df15 = df15[df15[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "\n",
        "  fig = make_subplots(rows=2, cols=1, \n",
        "                    subplot_titles=(f\"Transaction Values of {state} by District wise of {year}\",f\"Transaction Count of {state} by District wise of {year}\"))\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x =df15.groupby(\"DISTRICT_NAME\").sum().sort_values(\"TRANSACTION_AMOUNT\", ascending = False).index,\n",
        "         y = df15.groupby(\"DISTRICT_NAME\").sum().sort_values(\"TRANSACTION_AMOUNT\", ascending = False)[\"TRANSACTION_AMOUNT\"]),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x = df15.groupby(\"DISTRICT_NAME\").sum().sort_values(\"TRANSACTION_COUNT\", ascending = False).index,\n",
        "         y = df15.groupby(\"DISTRICT_NAME\").sum().sort_values(\"TRANSACTION_COUNT\", ascending = False)[\"TRANSACTION_COUNT\"]),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  fig.update_yaxes(title_text = \"Transaction Amount\", row = 1, col = 1)\n",
        "  fig.update_xaxes(title_text = \"District Name\", row = 1, col = 1)\n",
        "  fig.update_yaxes(title_text = \"Transaction Count\", row = 2, col = 1)\n",
        "  fig.update_xaxes(title_text = \"District Name\", row = 2, col = 1)\n",
        "\n",
        "\n",
        "  fig.update_layout(height = 1100, width=1000, title_text=f\"Districtwise aggrigation of {state}\", showlegend=False)\n",
        "  return fig\n",
        "\n",
        "\n",
        "def state_map_user(df, st, yr, qd):\n",
        "  from plotly.subplots import make_subplots\n",
        "  import plotly.graph_objects as go\n",
        "\n",
        "  #new_df6\n",
        "  state = st\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "  df16  = df\n",
        "  if state == \"All States\":\n",
        "    df16 = df16\n",
        "  elif state != \"All States\":\n",
        "    df16 = df16[df16[\"STATE_NAME\"] == state]\n",
        "\n",
        "  if year == \"All Years\":\n",
        "    df16 = df16\n",
        "  elif year != \"All Years\":\n",
        "    df16 = df16[df16[\"YEAR\"] == year]\n",
        "\n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df16 = df16\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df16 = df16[df16[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "\n",
        "  fig = make_subplots(rows=2, cols=1, \n",
        "                    subplot_titles=(f\"Registered users count of {state} by District wise of {year}\",f\"App opens count of {state} by District wise of {year}\"))\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x =df16.groupby(\"DISTRICT_NAME\").sum().sort_values(\"REGISTERED_USERS\", ascending = False).index,\n",
        "         y = df16.groupby(\"DISTRICT_NAME\").sum().sort_values(\"REGISTERED_USERS\", ascending = False)[\"REGISTERED_USERS\"]),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x = df16.groupby(\"DISTRICT_NAME\").sum().sort_values(\"APP_OPENS\", ascending = False).index,\n",
        "         y = df16.groupby(\"DISTRICT_NAME\").sum().sort_values(\"APP_OPENS\", ascending = False)[\"APP_OPENS\"]),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  fig.update_yaxes(title_text = \"Registered Users count\", row = 1, col = 1)\n",
        "  fig.update_xaxes(title_text = \"District Name\", row = 1, col = 1)\n",
        "  fig.update_yaxes(title_text = \"App Opensss Count\", row = 2, col = 1)\n",
        "  fig.update_xaxes(title_text = \"District Name\", row = 2, col = 1)\n",
        "\n",
        "\n",
        "  fig.update_layout(height = 1100, width=1000, title_text=f\"Districtwise aggrigation of {state}\", showlegend=False)\n",
        "  return fig\n",
        "\n",
        "\n",
        "def year_top_trans(df, yr, qd):\n",
        "  from plotly.subplots import make_subplots\n",
        "  import plotly.graph_objects as go\n",
        "  #new_df7\n",
        "  df17 = df\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "  if year == \"All Years\":\n",
        "    df17 = df17\n",
        "  elif year != \"All Years\":\n",
        "    df17 = df17 = df17[df17[\"YEAR\"] == year]\n",
        "\n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df17 = df17\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df17 = df17[df17[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "\n",
        "  fig = make_subplots(rows=3, cols=2, \n",
        "                      specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "                             [{\"type\": \"pie\"}, {\"type\": \"pie\"}],\n",
        "                             [{\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n",
        "                      subplot_titles=(f\"Top cities by Transaction count of {year}\",f\"Top cities by Transaction Amount of {year}\", \n",
        "                                      f\"Top Pincodes by Transaction count of {year}\", f\"Top Pincodes by Transaction Amount of {year}\", \n",
        "                                      f\"Top States by Transaction count of {year}\", f\"Top States by Transaction Amount of {year}\"))\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x = df17.iloc[:, :5].groupby(\"TOP_CITY_NAME\").sum().sort_values(\"CITY_TRANSACTION_COUNT\", ascending = False).head(10).index,\n",
        "             y = df17.iloc[:, :5].groupby(\"TOP_CITY_NAME\").sum().sort_values(\"CITY_TRANSACTION_COUNT\", ascending = False).head(10)[\"CITY_TRANSACTION_COUNT\"]),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x = df17.iloc[:, :5].groupby(\"TOP_CITY_NAME\").sum().sort_values(\"CITY_TRANSACTION_AMOUNT\", ascending = False).head(10).index,\n",
        "             y = df17.iloc[:, :5].groupby(\"TOP_CITY_NAME\").sum().sort_values(\"CITY_TRANSACTION_AMOUNT\", ascending = False).head(10)[\"CITY_TRANSACTION_AMOUNT\"]),\n",
        "      row=1, col=2\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(values =df17.iloc[:, [0, 1, 5, 6, 7]].groupby(\"TOP_PINCODE\").sum().sort_values(\"PINCODE_TRANSACTION_COUNT\", ascending = False).head(10)[\"PINCODE_TRANSACTION_COUNT\"],\n",
        "             labels = df17.iloc[:, [0, 1, 5, 6, 7]].groupby(\"TOP_PINCODE\").sum().sort_values(\"PINCODE_TRANSACTION_COUNT\", ascending = False).head(10).index),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(values =df17.iloc[:, [0, 1, 5, 6, 7]].groupby(\"TOP_PINCODE\").sum().sort_values(\"PINCODE_TRANSACTION_AMOUNT\", ascending = False).head(10)[\"PINCODE_TRANSACTION_AMOUNT\"],\n",
        "             labels = df17.iloc[:, [0, 1, 5, 6, 7]].groupby(\"TOP_PINCODE\").sum().sort_values(\"PINCODE_TRANSACTION_AMOUNT\", ascending = False).head(10).index),\n",
        "      row=2, col=2\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(y =df17.iloc[:, [0, 1, -3, -2, -1]].groupby(\"TOP_STATE_NAME\").sum().sort_values(\"STATE_TRANSACTION_COUNT\", ascending = False).head(10)[\"STATE_TRANSACTION_COUNT\"],\n",
        "             x = df17.iloc[:, [0, 1, -3, -2, -1]].groupby(\"TOP_STATE_NAME\").sum().sort_values(\"STATE_TRANSACTION_COUNT\", ascending = False).head(10).index),\n",
        "      row=3, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(y =df17.iloc[:, [0, 1, -3, -2, -1]].groupby(\"TOP_STATE_NAME\").sum().sort_values(\"STATE_TRANSACTION_AMOUNT\", ascending = False).head(10)[\"STATE_TRANSACTION_AMOUNT\"],\n",
        "             x = df17.iloc[:, [0, 1, -3, -2, -1]].groupby(\"TOP_STATE_NAME\").sum().sort_values(\"STATE_TRANSACTION_AMOUNT\", ascending = False).head(10).index),\n",
        "      row=3, col=2\n",
        "  )\n",
        "\n",
        "  #Updating X-axis label\n",
        "  fig.update_xaxes(title_text=\"City Name\", row=1, col=1)\n",
        "  fig.update_xaxes(title_text=\"City Name\", row=1, col=2)\n",
        "\n",
        "  fig.update_xaxes(title_text=\"State\", row=3, col=1)\n",
        "  fig.update_xaxes(title_text=\"State\", row=3, col=2)\n",
        "  #Updating Y-axis label\n",
        "  fig.update_yaxes(title_text=\"Transaction Count\", row=1, col=1)\n",
        "  fig.update_yaxes(title_text=\"Transaction Amount\", row=1, col=2)\n",
        "\n",
        "  fig.update_yaxes(title_text=\"Transaction Count\", row=3, col=1)\n",
        "  fig.update_yaxes(title_text=\"Transaction Amount\", row=3, col=2)\n",
        "\n",
        "  fig.update_layout(height = 1100, width=1000, title_text=f\"Top Transactions by City, Pincode, State of {year}\", showlegend=False)\n",
        "  return fig\n",
        "\n",
        "\n",
        "import geopy.geocoders\n",
        "from geopy.geocoders import Nominatim\n",
        "def loc(x):\n",
        "  try:\n",
        "    geolocator = Nominatim(user_agent='google', timeout=3)\n",
        "    location = geolocator.geocode(x)\n",
        "    return \",\".join(location.raw[\"display_name\"].split(\",\")[:-3])\n",
        "  except AttributeError:\n",
        "    return \"Not Known\"\n",
        "\n",
        "def state_top_trans(df, st, yr, qd):\n",
        "  from plotly.subplots import make_subplots\n",
        "  import plotly.graph_objects as go\n",
        "\n",
        "  df18 = df\n",
        "  state = st\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "  if state == \"All States\":\n",
        "    df18_district = df18\n",
        "    df18_pin = df18\n",
        "  elif state != \"All States\":\n",
        "    df18_district = df18[df18[\"STATE_NAME\"] == state]\n",
        "    df18_pin = df18[df18[\"STATE_NAME\"] == state]\n",
        "  \n",
        "\n",
        "  if year == \"All Years\":\n",
        "    df18_district = df18_district\n",
        "    df18_pin = df18_pin\n",
        "  elif year != \"All Years\":\n",
        "    df18_district = df18_district[df18_district[\"YEAR\"] == year]\n",
        "    df18_pin = df18_pin[df18_pin[\"YEAR\"] == year]\n",
        "\n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df18_district = df18_district\n",
        "    df18_pin = df18_pin\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df18_district = df18_district[df18_district[\"QUADRANT\"] == quadrant]\n",
        "    df18_pin = df18_pin[df18_pin[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "\n",
        "  #Step for adding the loccaion of the pincode\n",
        "  pin_loc = {}\n",
        "  for i in df18_pin[\"TOP_PINCODE\"].unique():\n",
        "    pin_loc[i] = i+\"-\"+loc(i)\n",
        "  df18_pin[\"PINCODE_WITH_LOCATION\"] = df18_pin[\"TOP_PINCODE\"].map(pin_loc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  fig = make_subplots(rows=2, cols=2, \n",
        "                      specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}],\n",
        "                             [{\"type\": \"pie\"}, {\"type\": \"pie\"}]],\n",
        "                      subplot_titles=(f\"Top Districts of the {state} by Transaction Count of {year}\",f\"Top cities of {state} by Transaction Amount of {year}\", f\"Top Pincodes of {state} by Transaction count of {year}\", f\"Top Pincodes of {state} by Transaction Amount of {year}\"))\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(labels= df18_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_TRANSACTION_COUNT\", ascending  = False).index,\n",
        "         values = df18_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_TRANSACTION_COUNT\", ascending  = False)[\"DISTRICT_TRANSACTION_COUNT\"]),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(labels= df18_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_TRANSACTION_AMOUNT\", ascending  = False).index,\n",
        "         values = df18_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_TRANSACTION_AMOUNT\", ascending  = False)[\"DISTRICT_TRANSACTION_AMOUNT\"]),\n",
        "      row=1, col=2\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(labels= df18_pin.groupby(\"PINCODE_WITH_LOCATION\").sum().sort_values(\"PINCODE_TRANSACTION_COUNT\", ascending  = False).head(10).index,\n",
        "         values = df18_pin.groupby(\"PINCODE_WITH_LOCATION\").sum().sort_values(\"PINCODE_TRANSACTION_COUNT\", ascending  = False).head(10)[\"PINCODE_TRANSACTION_COUNT\"]),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(labels= df18_pin.groupby(\"PINCODE_WITH_LOCATION\").sum().sort_values(\"PINCODE_TRANSACTION_AMOUNT\", ascending  = False).head(10).index,\n",
        "         values = df18_pin.groupby(\"PINCODE_WITH_LOCATION\").sum().sort_values(\"PINCODE_TRANSACTION_AMOUNT\", ascending  = False).head(10)[\"PINCODE_TRANSACTION_AMOUNT\"]),\n",
        "      row=2, col=2\n",
        "  )\n",
        "\n",
        "\n",
        "  fig.update_layout(height = 1100, width=1000, title_text=f\"Top Transactions by City, Pincode of {state} of {year}\", showlegend=False)\n",
        "  return fig\n",
        "\n",
        "\n",
        "\n",
        "def year_top_user(df, yr, qd):\n",
        "  from plotly.subplots import make_subplots\n",
        "  import plotly.graph_objects as go\n",
        "  #new_df9\n",
        "  df19 = df\n",
        "  df19_district = df19.iloc[:, :4]\n",
        "  df19_pin = df19.iloc[:, [0,1, 4, 5]]\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "\n",
        "  #filter for Districts\n",
        "  if year == \"All Years\":\n",
        "    df19_district = df19_district\n",
        "    df19_pin = df19_pin\n",
        "  elif year != \"All Years\":\n",
        "    df19_district = df19_district[df19_district[\"YEAR\"] == year]\n",
        "    df19_pin = df19_pin[df19_pin[\"YEAR\"] == year]\n",
        "\n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df19_district = df19_district\n",
        "    df19_pin = df19_pin\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df19_district = df19_district[df19_district[\"QUADRANT\"] == quadrant]\n",
        "    df19_pin = df19_pin[df19_pin[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "  #Step for adding the loccaion of the pincode\n",
        "  pin_loc = {}\n",
        "  for i in df19_pin[\"TOP_PINCODE\"].unique():\n",
        "    pin_loc[i] = i+\"-\"+loc(i)\n",
        "  df19_pin[\"PINCODE_WITH_LOCATION\"] = df19_pin[\"TOP_PINCODE\"].map(pin_loc)\n",
        "  \n",
        "\n",
        "\n",
        "  fig = make_subplots(rows=2, cols=1,\n",
        "                      specs=[[{\"type\": \"bar\"}], [{\"type\": \"pie\"}]],\n",
        "                      subplot_titles=(f\"Top cities by Registered Users of {year}\",f\"Top Pincode by Registered Users of {year}\"))\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x = df19_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_REGISTERED_USERS_COUNT\", ascending = False).head(10).index,\n",
        "             y = df19_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_REGISTERED_USERS_COUNT\", ascending = False).head(10)[\"DISTRICT_REGISTERED_USERS_COUNT\"]),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(labels = df19_pin.groupby(\"PINCODE_WITH_LOCATION\").sum().sort_values(\"PINCODE_REGISTERED_USERS_COUNT\", ascending = False).head(10).index,\n",
        "             values = df19_pin.groupby(\"PINCODE_WITH_LOCATION\").sum().sort_values(\"PINCODE_REGISTERED_USERS_COUNT\", ascending = False).head(10)[\"PINCODE_REGISTERED_USERS_COUNT\"]),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "\n",
        "  #Updating X-axis label\n",
        "  fig.update_xaxes(title_text=\"District Name\", row=1, col=1)\n",
        "\n",
        "  #Updating Y-axis label\n",
        "  fig.update_yaxes(title_text=\"Registered users Count\", row=1, col=1)\n",
        "\n",
        "  fig.update_layout(height = 1100, width=1000, title_text=f\"Top users by city and Pincode\", showlegend=False)\n",
        "  return fig\n",
        "\n",
        "\n",
        "def state_top_user(df, st, yr, qd):\n",
        "  from plotly.subplots import make_subplots\n",
        "  import plotly.graph_objects as go\n",
        "\n",
        "  df110 = df\n",
        "  df110_district = df110.iloc[:, 0:5]\n",
        "  df110_pin = df110.iloc[:, [0, 1, 2, 5, 6]]\n",
        "  state = st\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "    \n",
        "  if state == \"All States\":\n",
        "    df110_district = df110_district\n",
        "    df110_pin = df110_pin\n",
        "  elif state != \"All States\":\n",
        "    df110_district = df110_district[df110_district[\"STATE_NAME\"] == state]\n",
        "    df110_pin = df110_pin[df110_pin[\"STATE_NAME\"] == state]\n",
        "\n",
        "  if year == \"All Years\":\n",
        "    df110_district = df110_district\n",
        "    df110_pin = df110_pin\n",
        "  elif year != \"All Years\":\n",
        "    df110_district = df110_district[df110_district[\"YEAR\"] == year]\n",
        "    df110_pin = df110_pin[df110_pin[\"YEAR\"] == year]\n",
        "  \n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df110_district = df110_district\n",
        "    df110_pin = df110_pin\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df110_district = df110_district[df110_district[\"QUADRANT\"] == quadrant]\n",
        "    df110_pin = df110_pin[df110_pin[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "\n",
        "\n",
        "  #Step for adding the loccaion of the pincode\n",
        "  df_filter_user_st_pin_reg = df110_pin.groupby(\"TOP_PINCODE\").sum().sort_values(\"PINCODE_REGISTERED_USERS_COUNT\", ascending  = False).head(10)\n",
        "  df_filter_user_st_pin_reg[\"TOP_PINCODE\"] = df_filter_user_st_pin_reg.index\n",
        "  df_filter_user_st_pin_reg[\"PINCODE_LOCATION\"] = df_filter_user_st_pin_reg[\"TOP_PINCODE\"].apply(lambda x:loc(x))\n",
        "  pin_with_loc = {}\n",
        "  for i, j in zip(df_filter_user_st_pin_reg[\"PINCODE_LOCATION\"].tolist(), df_filter_user_st_pin_reg[\"TOP_PINCODE\"].tolist()):\n",
        "    pin_with_loc[j] = j+\"-\"+i\n",
        "  df_filter_user_st_pin_reg[\"PINCODE_WITH_LOCATION\"] = df_filter_user_st_pin_reg[\"TOP_PINCODE\"].map(pin_with_loc)\n",
        "\n",
        "  fig = make_subplots(rows=2, cols=1, \n",
        "                      specs=[[{\"type\": \"bar\"}], [{\"type\": \"pie\"}]],\n",
        "                      subplot_titles=(f\"Top Districts of {state} by Registered Users of {year}\", f\"Top Pincodes of {state} by Registered Users of {year}\"))\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x= df110_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_REGISTERED_USERS_COUNT\", ascending  = False).head(10).index,\n",
        "         y = df110_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_REGISTERED_USERS_COUNT\", ascending  = False).head(10)[\"DISTRICT_REGISTERED_USERS_COUNT\"]),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(labels= df_filter_user_st_pin_reg[\"PINCODE_WITH_LOCATION\"],\n",
        "         values = df_filter_user_st_pin_reg[\"PINCODE_REGISTERED_USERS_COUNT\"]),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "  fig.update_layout(height = 1100, width=1000, title_text=f\"Top Transactions by City, Pincode of {state} of {year}\", showlegend=False)\n",
        "  return fig"
      ],
      "metadata": {
        "id": "1JvFQPpYTXoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def state_top_user(df, st, yr, qd):\n",
        "  from plotly.subplots import make_subplots\n",
        "  import plotly.graph_objects as go\n",
        "\n",
        "  df110 = df\n",
        "  df110_district = df110.iloc[:, 0:5]\n",
        "  df110_pin = df110.iloc[:, [0, 1, 2, 5, 6]]\n",
        "  state = st\n",
        "  year = yr\n",
        "  quadrant = qd\n",
        "    \n",
        "  if state == \"All States\":\n",
        "    df110_district = df110_district\n",
        "    df110_pin = df110_pin\n",
        "  elif state != \"All States\":\n",
        "    df110_district = df110_district[df110_district[\"STATE_NAME\"] == state]\n",
        "    df110_pin = df110_pin[df110_pin[\"STATE_NAME\"] == state]\n",
        "\n",
        "  if year == \"All Years\":\n",
        "    df110_district = df110_district\n",
        "    df110_pin = df110_pin\n",
        "  elif year != \"All Years\":\n",
        "    df110_district = df110_district[df110_district[\"YEAR\"] == year]\n",
        "    df110_pin = df110_pin[df110_pin[\"YEAR\"] == year]\n",
        "  \n",
        "  if quadrant == \"All Quadrants\":\n",
        "    df110_district = df110_district\n",
        "    df110_pin = df110_pin\n",
        "  elif quadrant != \"All Quadrants\":\n",
        "    df110_district = df110_district[df110_district[\"QUADRANT\"] == quadrant]\n",
        "    df110_pin = df110_pin[df110_pin[\"QUADRANT\"] == quadrant]\n",
        "\n",
        "\n",
        "\n",
        "  #Step for adding the loccaion of the pincode\n",
        "  df_filter_user_st_pin_reg = df110_pin.groupby(\"TOP_PINCODE\").sum().sort_values(\"PINCODE_REGISTERED_USERS_COUNT\", ascending  = False).head(10)\n",
        "  df_filter_user_st_pin_reg[\"TOP_PINCODE\"] = df_filter_user_st_pin_reg.index\n",
        "  df_filter_user_st_pin_reg[\"PINCODE_LOCATION\"] = df_filter_user_st_pin_reg[\"TOP_PINCODE\"].apply(lambda x:loc(x))\n",
        "  pin_with_loc = {}\n",
        "  for i, j in zip(df_filter_user_st_pin_reg[\"PINCODE_LOCATION\"].tolist(), df_filter_user_st_pin_reg[\"TOP_PINCODE\"].tolist()):\n",
        "    pin_with_loc[j] = j+\"-\"+i\n",
        "  df_filter_user_st_pin_reg[\"PINCODE_WITH_LOCATION\"] = df_filter_user_st_pin_reg[\"TOP_PINCODE\"].map(pin_with_loc)\n",
        "\n",
        "  fig = make_subplots(rows=2, cols=1, \n",
        "                      specs=[[{\"type\": \"bar\"}], [{\"type\": \"pie\"}]],\n",
        "                      subplot_titles=(f\"Top Districts of {state} by Registered Users of {year}\", f\"Top Pincodes of {state} by Registered Users of {year}\"))\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x= df110_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_REGISTERED_USERS_COUNT\", ascending  = False).head(10).index,\n",
        "         y = df110_district.groupby(\"TOP_DISTRICT_NAME\").sum().sort_values(\"DISTRICT_REGISTERED_USERS_COUNT\", ascending  = False).head(10)[\"DISTRICT_REGISTERED_USERS_COUNT\"]),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Pie(labels= df_filter_user_st_pin_reg[\"PINCODE_WITH_LOCATION\"],\n",
        "         values = df_filter_user_st_pin_reg[\"PINCODE_REGISTERED_USERS_COUNT\"]),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "  fig.update_layout(height = 1100, width=1000, title_text=f\"Top Transactions by City, Pincode of {state} of {year}\", showlegend=False)\n",
        "  return fig\n"
      ],
      "metadata": {
        "id": "D5DnWMq-mkBs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -q\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "8QtE-Lk_4J9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mock_app.py\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from etl import new_df1, new_df2, new_df3, new_df4, new_df5, new_df6, new_df7, new_df8, new_df9, new_df10\n",
        "from visuvalization import *\n",
        "def main():\n",
        "  st.markdown(\"<h1 style='text-align: center; color: red;'>PHONEPE PULSE DATA VISUVALIZATION</h1>\", unsafe_allow_html=True)\n",
        "  \n",
        "  st.markdown(\"<h2 style='text-align: center; color: red;'>YEARWISE VISUVALIZATION</h2>\", unsafe_allow_html=True)\n",
        "  col1, col2, col3 = st.columns(3)\n",
        "  with col1:\n",
        "    yr = st.selectbox(\"Select Year\", [\"All Years\", 2018, 2019, 2020, 2021, 2022], key = \"yearwise_year\")\n",
        "  with col2:\n",
        "    qd = st.selectbox(\"Select Quadrant\", [\"All Quadrants\", 1, 2, 3, 4], key = \"yearwise_quadrant\")\n",
        "  with col3:\n",
        "    type1 = st.selectbox(\"Select type\", [\"Aggrigated values\", \"Top Values\"])\n",
        "  type2 = st.radio(\"Select data\", [\"Transaction data\", \"Users data\"])\n",
        "  if type1 == \"Aggrigated values\" and type2 == \"Transaction data\":\n",
        "    visual1 = year_agg_trans(new_df1, yr, qd)\n",
        "  elif type1 == \"Aggrigated values\" and type2 == \"Users data\":\n",
        "    visual1 = year_agg_user(new_df3, yr, qd)\n",
        "  elif type1 == \"Top Values\" and type2 == \"Transaction data\":\n",
        "    visual1 = year_top_trans(new_df7, yr, qd)\n",
        "  elif type1 == \"Top Values\" and type2 == \"Users data\":\n",
        "    visual1 = year_top_user(new_df9, yr, qd)\n",
        "  \n",
        "  st.write(visual1)\n",
        "  st.markdown(\"<h2 style='text-align: center; color: red;'>STATEWISE MAP VISUVALIZATION</h2>\", unsafe_allow_html=True)\n",
        "  col4, col5, col6 = st.columns(3)\n",
        "  with col4:\n",
        "    state_1 = st.selectbox(\"Select the state\", [\"All States\",'Mizoram','Lakshadweep','Meghalaya','Chhattisgarh','Karnataka','Odisha','Kerala','Goa','Uttarakhand','Punjab','Andhra Pradesh','Tamil Nadu',\n",
        "    'Arunachal Pradesh','Chandigarh','Madhya Pradesh','West Bengal', 'Assam','Uttar Pradesh','Gujarat','Manipur','Tripura','Puducherry','Bihar','Nagaland','Rajasthan','Delhi',\n",
        "    'Maharashtra','Telangana','Himachal Pradesh','Jharkhand','Haryana','Ladakh','Sikkim'])\n",
        "  with col5:\n",
        "    yr2 = st.selectbox(\"Select Year\", [\"All Years\", 2018, 2019, 2020, 2021, 2022], key = \"map_year\")\n",
        "  with col6:\n",
        "    qd2 = st.selectbox(\"Select Quadrant\", [\"All Quadrants\", 1, 2, 3, 4], key = \"map_quadrant\")\n",
        "  visual2 = state_agg_trans(new_df2, new_df4, state_1, yr2, qd2)\n",
        "  st.write(visual2)\n",
        "\n",
        "  st.markdown(\"<h2 style='text-align: center; color: red;'>STATEWISE VISUVALIZATION</h2>\", unsafe_allow_html=True)\n",
        "  col7, col8, col9, col10= st.columns(4)\n",
        "  with col7:\n",
        "    state_2 = st.selectbox(\"Select State\", [\"All States\", 'Mizoram','Lakshadweep','Meghalaya','Chhattisgarh','Karnataka','Odisha','Kerala','Goa','Uttarakhand','Punjab','Andhra Pradesh','Tamil Nadu','Arunachal Pradesh',\n",
        "    'Chandigarh','Madhya Pradesh','West Bengal','Assam','Uttar Pradesh','Gujarat','Manipur','Tripura','Puducherry','Bihar','Jammu Kashmir','Nagaland','Rajasthan','Delhi','Maharashtra','Telangana',\n",
        "    'Andaman Nicobar Islands','Himachal Pradesh','Jharkhand','Haryana','Ladakh','Sikkim','Dadra Nagar Haveli Daman Diu'], key = \"state_2\")\n",
        "  with col8:\n",
        "    yr3 = st.selectbox(\"Select Year\", [\"All Years\", 2018, 2019, 2020, 2021, 2022], key = \"state_year\")\n",
        "  with col9:\n",
        "    qd3 = st.selectbox(\"Select Quadrant\", [\"All Quadrants\", 1, 2, 3, 4], key = \"state_quadrant\")\n",
        "  with col10:\n",
        "    type4 = st.selectbox(\"Select Type\", [\"Aggrigated values\", \"Top values\"], key = \"state_type4\")\n",
        "  type5 = st.radio(\"Select Data Type\", [\"Transaction Data\", \"User Data\"], key = \"state_type5\")\n",
        "  if type4 == \"Aggrigated values\" and type5 == \"Transaction Data\":\n",
        "    visuval3 = state_map_trans(new_df5, state_2, yr3, qd3)\n",
        "  elif type4 == \"Aggrigated values\" and type5 == \"User Data\":\n",
        "    visuval3 = state_map_user(new_df6, state_2, yr3, qd3)\n",
        "  elif type4 == \"Top values\" and type5 == \"Transaction Data\":\n",
        "    visuval3 = state_top_trans(new_df8, state_2, yr3, qd3)\n",
        "  elif type4 == \"Top values\" and type5 == \"User Data\":\n",
        "    visuval3 = state_top_user(new_df10, state_2, yr3, qd3)\n",
        "\n",
        "   \n",
        "  st.write(visuval3)\n",
        "\n",
        "  new_df1_csv = new_df1.to_csv()\n",
        "  new_df2_csv = new_df2.to_csv()\n",
        "  new_df3_csv = new_df3.to_csv()\n",
        "  new_df4_csv = new_df4.to_csv()\n",
        "  new_df5_csv = new_df5.to_csv()\n",
        "  new_df6_csv = new_df6.to_csv()\n",
        "  new_df7_csv = new_df7.to_csv()\n",
        "  new_df8_csv = new_df8.to_csv()\n",
        "  new_df9_csv = new_df9.to_csv()\n",
        "  new_df10_csv = new_df10.to_csv()\n",
        "\n",
        "  st.write(\"For reference data click the download butten ...\")\n",
        "  if st.button(\"Download Data\"):\n",
        "    st.download_button(\"Download Table 1 as CSV\",data = new_df1_csv,file_name = \"Aggrigation_transaction_yearwise.csv\",mime='text/csv')\n",
        "    st.download_button(\"Download Table 2 as CSV\",data = new_df2_csv,file_name = \"Aggrigation_transaction_statewise.csv\",mime='text/csv')\n",
        "    st.download_button(\"Download Table 3 as CSV\",data = new_df3_csv,file_name = \"Aggrigation_user_yearwise.csv\",mime='text/csv')\n",
        "    st.download_button(\"Download Table 4 as CSV\",data = new_df4_csv,file_name = \"Aggrigation_user_statewise.csv\",mime='text/csv')\n",
        "    st.download_button(\"Download Table 5 as CSV\",data = new_df5_csv,file_name = \"Map_transaction_statewise.csv\",mime='text/csv')\n",
        "    st.download_button(\"Download Table 6 as CSV\",data = new_df6_csv,file_name = \"Map_user_statewise.csv\",mime='text/csv')\n",
        "    st.download_button(\"Download Table 7 as CSV\",data = new_df7_csv,file_name = \"Top_transaction_yearwise.csv\",mime='text/csv')\n",
        "    st.download_button(\"Download Table 8 as CSV\",data = new_df8_csv,file_name = \"Top_transaction_statewise.csv\",mime='text/csv')\n",
        "    st.download_button(\"Download Table 9 as CSV\",data = new_df9_csv,file_name = \"Top_user_yearwise.csv\",mime='text/csv')\n",
        "    st.download_button(\"Download Table 10 as CSV\",data = new_df10_csv,file_name = \"Top_user_statewise.csv\",mime='text/csv')\n",
        "\n",
        "\n",
        "\n",
        "  st.markdown(\"<h6 style='text-align: center; color: red;'>CREATED BY TAMIZHARASAN GOVINDASAMY</h6>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "eKANSTZVljha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok==4.1.1"
      ],
      "metadata": {
        "id": "lTkx2EAJEphe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2Kjk1sNkgtHmhrvADxwoX7sWOtY_87unGjkb4XkX7h8bLv2fs"
      ],
      "metadata": {
        "id": "Kpz0gR4uEsBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -qq ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "id": "qYWY29gXEvZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "id": "1-TpPawpEye0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/mock_app.py "
      ],
      "metadata": {
        "id": "OvJZLc9TE1N-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}